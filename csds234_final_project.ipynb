{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f925552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Import data\n",
    "# train = pd.read_csv(\"./Downloads/train (2).csv\")\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove empty tweets\n",
    "empty = np.where(train['text'] == \"\")\n",
    "train.drop(train.index[empty], inplace = True, axis = 0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Clean tweets\n",
    "import re, string\n",
    "\n",
    "def clean(text):\n",
    "    # make all text lowercase\n",
    "    cleaned = text.casefold()\n",
    "    # remove non-printable characters\n",
    "    cleaned = ''.join([word for word in cleaned if word in string.printable])\n",
    "    # remove character references\n",
    "    cleaned = re.sub(r'&[a-zA-Z]+;?', '', cleaned)\n",
    "    # remove URL\n",
    "    cleaned = re.sub(r'((?:https?|ftp|file)://[-\\w\\d+=&@#/%?~|!:;\\.,]*)', '', cleaned)\n",
    "    # remove HTML tags\n",
    "    cleaned = re.sub(r'((?:https?|ftp|file)://[-\\w\\d+=&@#/%?~|!:;\\.,]*)', '', cleaned)\n",
    "    # remove mixtures of text and numeric\n",
    "    cleaned = re.sub(r'\\w*\\d+\\w*', '', cleaned)\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "train['text'] = train['text'].apply(clean)\n",
    "\n",
    "print(train.iloc[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefdf71",
   "metadata": {},
   "source": [
    "# TFIDF and CountVectorizer Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313aace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize contents of all tweets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "countvectorizer = CountVectorizer(analyzer ='word', stop_words='english')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "\n",
    "count_wm = countvectorizer.fit_transform(train['text'])\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(train['text'])\n",
    "\n",
    "#retrieve the terms found in the corpora\n",
    "count_tokens = countvectorizer.get_feature_names()\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "\n",
    "df_countvect = pd.DataFrame(data = count_wm.toarray(),index = list(train.index.values) ,columns = count_tokens)\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = list(train.index.values) ,columns = tfidf_tokens)\n",
    "\n",
    "print(\"Count Vectorizer\\n\")\n",
    "print(df_countvect)\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TFIDF representation\n",
    "df_tfidfvect.to_csv('df_tfidfvect.csv', index = False)\n",
    "\n",
    "# Save countVectorizer representation\n",
    "df_countvect.to_csv('df_countvect.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b00c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidfvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b7574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countvect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5f8ee",
   "metadata": {},
   "source": [
    "# Brown Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608adff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install brown-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brown_clustering import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from brown_clustering import BigramCorpus, BrownClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_brown = train.drop(columns = ['keyword', 'location', 'id','target'])\n",
    "# train_brown = train_brown.iloc[0:100]\n",
    "train_brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "data_tokenized = [w.lower() for w in train_brown['text']]\n",
    "data_tokenized = [tokenizer.tokenize(i) for i in data_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d055fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23537a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = BigramCorpus(data_tokenized, 0.001)\n",
    "clustering = BrownClustering(corpus,800)\n",
    "clusters = clustering.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d23e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.DataFrame(clusters)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e55fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Brown clusters to csv\n",
    "clusters.to_csv('brown_clusters.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import brown clusters\n",
    "bc = pd.read_csv('brown_clusters.csv', low_memory=False)\n",
    "\n",
    "# Format into list of lists\n",
    "bc = bc.values.tolist()\n",
    "brown_clusters = [[j for j in i if str(j)!='nan'] for i in bc]\n",
    "\n",
    "brown_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8095ef",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ff9ca",
   "metadata": {},
   "source": [
    "### 1) TESTING RUNTIMES OF DIFFERENT QUERY SIZES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadacc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some query functions\n",
    "\n",
    "import time\n",
    "from random import sample\n",
    "\n",
    "def query(data, keywords):\n",
    "    ''' BASIC QUERY METHOD\n",
    "    INPUT:\n",
    "    keywords[]: list of keywords\n",
    "    \n",
    "    OUTPUT:\n",
    "    runtime: time it took to run the query\n",
    "    matches: all tweets containing at least 1 of those keywords\n",
    "    '''\n",
    "    \n",
    "    # keep track of time\n",
    "    start = time.time()\n",
    "    \n",
    "    matches = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        if keyword in data.columns.astype(str):\n",
    "            matches.append(data.index[data[keyword] > 0].tolist())\n",
    "    \n",
    "    # print out time it took to run\n",
    "    end = time.time()\n",
    "    runtime = end-start\n",
    "    \n",
    "    return runtime, matches\n",
    "\n",
    "\n",
    "def query_brown(keywords):\n",
    "    ''' QUERY METHOD FOR BROWN REPRESENTION\n",
    "    INPUT:\n",
    "    keywords[]: list of keywords\n",
    "    \n",
    "    OUTPUT: \n",
    "    runtime: time it took to run the brown query\n",
    "    matches: all tweets containing at least 1 keyword from new_kw\n",
    "    \n",
    "    1) Search brown_clusters for all clusters containing the keywords passed in\n",
    "    2) Concatenate all those clusters into one list\n",
    "    3) Query TFIDF representation using list of new keywords (new_kw)\n",
    "    '''\n",
    "    # keep track of time\n",
    "    start = time.time()\n",
    "    \n",
    "    new_kw = []\n",
    "    for keyword in keywords:\n",
    "        for cluster in brown_clusters:\n",
    "            if keyword in cluster:\n",
    "                new_kw.append(cluster)\n",
    "    # Flatten new_kw\n",
    "    new_kw = [kw for kwlist in new_kw for kw in kwlist]\n",
    "#     print(new_kw)\n",
    "    \n",
    "    matches = query(df_tfidfvect, new_kw)[1]\n",
    "    \n",
    "    # print out time it took to run\n",
    "    end = time.time()\n",
    "    runtime = end-start\n",
    "\n",
    "    return(runtime, matches)\n",
    "        \n",
    "\n",
    "def test_querysize(iterations, querysize):\n",
    "    ''' TEST DIFFERENT SIZEES OF QUERIES ON ALL DATA REPRESENTATIONS\n",
    "    INPUT:\n",
    "    iterations: number of times to run query\n",
    "    querysize: number of keywords in each query\n",
    "    \n",
    "    OUTPUT: \n",
    "    countvect_times: list of time it took per iteration to query countvect\n",
    "    tfidf_times: list of time it took per iteration to query tfidf\n",
    "    brown_times: list of time it took per iteration to query brown\n",
    "    \n",
    "    1) Get all common keys between countvect and tfidfvect\n",
    "    2) randomly sample those common keys for <querysize> keywords\n",
    "    3) query each representation with randomly sampled keywords <iterations> times\n",
    "    4) add all times to lists and return the list\n",
    "    '''\n",
    "    \n",
    "    common_keys = list(set(df_countvect) & set(df_tfidfvect))\n",
    "    countvect_times = []\n",
    "    tfidf_times = []\n",
    "    brown_times = []\n",
    "    for i in range(iterations):\n",
    "        print(f\"iter {i}\")\n",
    "        query_words = sample(common_keys,querysize)\n",
    "        countvect_times.append(query(df_countvect, query_words)[0])\n",
    "        tfidf_times.append(query(df_tfidfvect, query_words)[0])\n",
    "        brown_times.append(query_brown(query_words)[0])\n",
    "    return countvect_times, tfidf_times, brown_times\n",
    "\n",
    "def avg_runtimes(test_querysize_output):\n",
    "    '''\n",
    "    TAKE OUTPUT OF test_querysize AND GET AVERAGES OF EACH LIST AND APPEND TO DICTIONARY\n",
    "    '''\n",
    "    timesDict = {\"countvect\": [],\n",
    "                \"tfidf\": [],\n",
    "                \"brown\": []}\n",
    "    timesDict['countvect'].append(sum(test_querysize_output[0]) / len(test_querysize_output[0]))\n",
    "    timesDict['tfidf'].append(sum(test_querysize_output[1]) / len(test_querysize_output[1]))\n",
    "    timesDict['brown'].append(sum(test_querysize_output[2]) / len(test_querysize_output[2]))\n",
    "    \n",
    "    return timesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98eb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### some testing\n",
    "# test1 = query(df_countvect, [\"ablaze\", \"_bookofdaniel\", 'earthquake', 'rat', ''])\n",
    "# test2 = query(df_tfidfvect, [\"ablaze\", \"_bookofdaniel\", 'earthquake', 'rat'])\n",
    "# test3 = query_brown(['airlines', 'top', 'otm'])\n",
    "# print(test1)\n",
    "# print(test2)\n",
    "# print(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9cacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load defaults\n",
    "# Import brown clusters\n",
    "bc = pd.read_csv('brown_clusters.csv', low_memory=False)\n",
    "\n",
    "# Format into list of lists\n",
    "bc = bc.values.tolist()\n",
    "brown_clusters = [[j for j in i if str(j)!='nan'] for i in bc]\n",
    "\n",
    "# Import CountVectorizer and TFIDF\n",
    "df_tfidfvect = pd.read_csv('df_tfidfvect.csv')\n",
    "df_countvect = pd.read_csv('df_countvect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing tests\n",
    "runtimes_20_1 = test_querysize(iterations = 20, querysize = 1)\n",
    "runtimes_20_2 = test_querysize(iterations = 20, querysize = 2)\n",
    "runtimes_20_3 = test_querysize(iterations = 20, querysize = 3)\n",
    "runtimes_20_4 = test_querysize(iterations = 20, querysize = 4)\n",
    "runtimes_20_5 = test_querysize(iterations = 20, querysize = 5)\n",
    "runtimes_20_6 = test_querysize(iterations = 20, querysize = 6)\n",
    "runtimes_20_7 = test_querysize(iterations = 20, querysize = 7)\n",
    "runtimes_20_8 = test_querysize(iterations = 20, querysize = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faae33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get avg runtimes of different query sizes\n",
    "avg_rt_20_1 = avg_runtimes(runtimes_20_1)\n",
    "avg_rt_20_2 = avg_runtimes(runtimes_20_2)\n",
    "avg_rt_20_3 = avg_runtimes(runtimes_20_3)\n",
    "avg_rt_20_4 = avg_runtimes(runtimes_20_4)\n",
    "avg_rt_20_5 = avg_runtimes(runtimes_20_5)\n",
    "avg_rt_20_6 = avg_runtimes(runtimes_20_6)\n",
    "avg_rt_20_7 = avg_runtimes(runtimes_20_7)\n",
    "avg_rt_20_8 = avg_runtimes(runtimes_20_8)\n",
    "\n",
    "\n",
    "print(f\"avg_rt_20_1: {avg_rt_20_1}\")\n",
    "print(f\"avg_rt_20_2: {avg_rt_20_2}\")\n",
    "print(f\"avg_rt_20_3: {avg_rt_20_3}\")\n",
    "print(f\"avg_rt_20_4: {avg_rt_20_4}\")\n",
    "print(f\"avg_rt_20_5: {avg_rt_20_5}\")\n",
    "print(f\"avg_rt_20_6: {avg_rt_20_6}\")\n",
    "print(f\"avg_rt_20_7: {avg_rt_20_7}\")\n",
    "print(f\"avg_rt_20_8: {avg_rt_20_8}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5465ccc",
   "metadata": {},
   "source": [
    "### 2) TESTING RELATIONSHIP BETWEEN REPRESENTATION TYPE AND DATA SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to store data representations of different size\n",
    "from brown_clustering import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from brown_clustering import BigramCorpus, BrownClustering\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def perform_brown_clustering(data, name):\n",
    "    ''' SAVES A CSV OF BROWN CLUSTERING ON A SIZE VARIANT OF train\n",
    "    INPUT:\n",
    "    data: some slicing of train\n",
    "    name: what you want to name the data\n",
    "    \n",
    "    OUTPUT:\n",
    "    downloads a brown clusting of name \"<name>_brown.csv\"\n",
    "    '''\n",
    "    \n",
    "    data_brown = data.drop(columns = ['keyword', 'location', 'id','target'])\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    data_tokenized = [w.lower() for w in data_brown['text']]\n",
    "    data_tokenized = [tokenizer.tokenize(i) for i in data_tokenized]\n",
    "    corpus = BigramCorpus(data_tokenized, 0.001)\n",
    "    clustering = BrownClustering(corpus,800)\n",
    "    clusters = clustering.train()\n",
    "    clusters = pd.DataFrame(clusters)\n",
    "    clusters.to_csv(f'test2/{name}_brown.csv', index = False)\n",
    "\n",
    "def perform_countvec_n_tfidf(data, name):\n",
    "    ''' SAVE CSV'S OF TFIDF AND COUNTVECT REPRESENTATIONS OF SIZE VARIANTS OF train\n",
    "    INPUT:\n",
    "    data: some slicing of train\n",
    "    name: what you want to name the data\n",
    "    \n",
    "    OUTPUT:\n",
    "    downloads a TFIDF of name \"<name>_tfidf.csv\"\n",
    "    downloads a CountVect of name \"<name>_countvect.csv\"\n",
    "    '''\n",
    "        \n",
    "    countvectorizer = CountVectorizer(analyzer ='word', stop_words='english')\n",
    "    tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')\n",
    "\n",
    "    count_wm = countvectorizer.fit_transform(data['text'])\n",
    "    tfidf_wm = tfidfvectorizer.fit_transform(data['text'])\n",
    "\n",
    "    #retrieve the terms found in the corpora\n",
    "    count_tokens = countvectorizer.get_feature_names()\n",
    "    tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "\n",
    "    df_countvect = pd.DataFrame(data = count_wm.toarray(),index = list(data.index.values) ,columns = count_tokens)\n",
    "    df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = list(data.index.values) ,columns = tfidf_tokens)\n",
    "    \n",
    "    df_tfidfvect.to_csv(f'test2/{name}_tfidf.csv', index = False)\n",
    "    df_countvect.to_csv(f'test2/{name}_countvect.csv', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6864b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 5 different amounts of tweets\n",
    "\n",
    "# 1500 tweets\n",
    "data = train[0:1500]\n",
    "perform_brown_clustering(data, \"1500tweets\")\n",
    "perform_countvec_n_tfidf(data, \"1500tweets\")\n",
    "\n",
    "# 3000 tweets\n",
    "data = train[0:3000]\n",
    "perform_brown_clustering(data, \"3000tweets\")\n",
    "perform_countvec_n_tfidf(data, \"3000tweets\")\n",
    "\n",
    "# 4500 tweets\n",
    "data = train[0:4500]\n",
    "perform_brown_clustering(data, \"4500tweets\")\n",
    "perform_countvec_n_tfidf(data, \"4500tweets\")\n",
    "\n",
    "# 6000 tweets\n",
    "data = train[0:6000]\n",
    "perform_brown_clustering(data, \"6000tweets\")\n",
    "perform_countvec_n_tfidf(data, \"6000tweets\")\n",
    "\n",
    "# full dataset (7613) is already done\n",
    "data = train\n",
    "perform_brown_clustering(data, \"7613tweets\")\n",
    "perform_countvec_n_tfidf(data, \"7613tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa71ab",
   "metadata": {},
   "source": [
    "### 3) TEST RELATIONSHIP BETWEEN DATA SIZE AND QUERY TIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f77e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_datasize(datasize, querysize):\n",
    "    ''' FOR GIVEN DATASIZE, TEST QUERY TIME\n",
    "    INPUT:\n",
    "    datasize: number of tweets in dataset\n",
    "    - string matching the name of data stored\n",
    "    querysize: number of keywords in query\n",
    "    \n",
    "    OUTPUT:\n",
    "    countvect_times: list of time it took per iteration to query countvect\n",
    "    tfidf_times: list of time it took per iteration to query tfidf\n",
    "    brown_times: list of time it took per iteration to query brown\n",
    "    \n",
    "    1) Load in all data relevant to the given datasize\n",
    "    2) randomly sample <querysize> keywords as query \n",
    "    3) run 10 iterations with randomly sampled query on each data repesentation\n",
    "    4) return list of querytimes for each representation\n",
    "    '''\n",
    "    # Load in the correct datasize\n",
    "    bc = pd.read_csv(f'test2/{datasize}_brown.csv', low_memory=False)\n",
    "    bc = bc.values.tolist()\n",
    "    brown_clusters = [[j for j in i if str(j)!='nan'] for i in bc]\n",
    "    df_tfidfvect = pd.read_csv(f'{datasize}_tfidf.csv')\n",
    "    df_countvect = pd.read_csv(f'{datasize}_countvect.csv')\n",
    "\n",
    "    # Perform query\n",
    "    common_keys = list(set(df_countvect) & set(df_tfidfvect))\n",
    "    countvect_times = []\n",
    "    tfidf_times = []\n",
    "    brown_times = []\n",
    "    for i in range(20):\n",
    "        print(f\"iter {i}\")\n",
    "        query_words = sample(common_keys,querysize)\n",
    "        countvect_times.append(query(df_countvect, query_words)[0])\n",
    "        tfidf_times.append(query(df_tfidfvect, query_words)[0])\n",
    "        brown_times.append(query_brown(query_words)[0])\n",
    "    return countvect_times, tfidf_times, brown_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc445918",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1500 = test_datasize('1500tweets', 3)\n",
    "size3000 = test_datasize('3000tweets', 3)\n",
    "size4500 = test_datasize('4500tweets', 3)\n",
    "size6000 = test_datasize('6000tweets', 3)\n",
    "size7613 = test_datasize('7613tweets', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1500_avg = avg_runtimes(size1500)\n",
    "size3000_avg = avg_runtimes(size3000)\n",
    "size4500_avg = avg_runtimes(size4500)\n",
    "size6000_avg = avg_runtimes(size6000)\n",
    "size7613_avg = avg_runtimes(size7613)\n",
    "\n",
    "\n",
    "print(f\"size1500: {size1500_avg}\")\n",
    "print(f\"size3000: {size3000_avg}\")\n",
    "print(f\"size4500: {size4500_avg}\")\n",
    "print(f\"size6000: {size6000_avg}\")\n",
    "print(f\"size7613: {size7613_avg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4bfd06",
   "metadata": {},
   "source": [
    "# PLOT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b882b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1)Runtimes of different query sizes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "querysize = np.array([1,2,3,4,5,6,7,8])\n",
    "\n",
    "# countvect\n",
    "countvect_avg_runtimes = np.array([0.01724226474761963, .02783757448196411, .03952515125274658, .051900172233581544, .06796498298645019, .08448317050933837, .09484838247299195,.1126623272895813 ])\n",
    "plt.plot(querysize, countvect_avg_runtimes, label=\"CountVect\")\n",
    "\n",
    "# tfidf\n",
    "tfidf_avg_runtimes = np.array([.014464783668518066, .02550452947616577, .0376893401145935, .04739259481430054, .06234642267227173, .08207361698150635, .09202570915222168, .10178455114364623])\n",
    "plt.plot(querysize, tfidf_avg_runtimes, label=\"TFIDF\")\n",
    "\n",
    "# brown\n",
    "brown_avg_runtimes = np.array([7.319691252708435, 24.610164976119997, 33.989655470848085, 55.077748489379886, 77.4521006822586, 110.89618942737579, 129.91393275260924, 145.31892223358153])\n",
    "plt.plot(querysize, brown_avg_runtimes, label=\"Brown\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Runtime of Different Data Representations with Varying Query Size\")\n",
    "plt.xlabel(\"Number of Keywords in Query\")\n",
    "plt.ylabel(\"Runtime (sec)\")\n",
    "plt.legend(bbox_to_anchor=(1.1,1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF and countvect together\n",
    "plt.plot(querysize, countvect_avg_runtimes, label=\"CountVect\")\n",
    "plt.plot(querysize, tfidf_avg_runtimes, label=\"TFIDF\")\n",
    "plt.title(\"Runtime of Different Data Representations with Varying Query Size\")\n",
    "plt.xlabel(\"Number of Keywords in Query\")\n",
    "plt.ylabel(\"Runtime (sec)\")\n",
    "plt.legend(bbox_to_anchor=(1.1,1.05))\n",
    "plt.show()\n",
    "\n",
    "# Just brown\n",
    "plt.plot(querysize, brown_avg_runtimes, label=\"Brown\", color='green')\n",
    "plt.title(\"Runtime of Different Data Representations with Varying Query Size\")\n",
    "plt.xlabel(\"Number of Keywords in Query\")\n",
    "plt.ylabel(\"Runtime (sec)\")\n",
    "plt.legend(bbox_to_anchor=(1.1,1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2)Relationship between number of tweets and size of data representation\n",
    "\n",
    "numTweets = np.array([1500, 3000, 4500, 6000, 7613])\n",
    "\n",
    "# countvect\n",
    "countvect_sizes = np.array([4.8, 50.3, 100, 160, 239])\n",
    "plt.plot(numTweets, countvect_sizes, label=\"CountVect\")\n",
    "\n",
    "# tfidf\n",
    "tfidf_sizes = np.array([29.8, 101, 201, 321, 478])\n",
    "plt.plot(numTweets, tfidf_sizes, label=\"TFIDF\")\n",
    "\n",
    "# brown\n",
    "brown_sizes = np.array([.35546875, 1.05, 1.83, 2.73, 3.6]) + tfidf_sizes\n",
    "plt.plot(numTweets, brown_sizes, label=\"Brown\")\n",
    "\n",
    "plt.title(\"Size of Different Data Representations with Varying Number of Tweets Stored\")\n",
    "plt.xlabel(\"Number of Tweets Stored\")\n",
    "plt.ylabel(\"Size (MB)\")\n",
    "plt.legend(bbox_to_anchor=(1.1,1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffdb6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 3) Relationship between number of tweets and query time\n",
    "\n",
    "numTweets = np.array([1500, 3000, 4500, 6000, 7613])\n",
    "\n",
    "# countvect\n",
    "countvect_avg_runtimes = np.array([.013947844505310059, .024823665618896484, .028082501888275147, .03503996133804321, .04536161422729492])\n",
    "plt.plot(numTweets, countvect_avg_runtimes, label=\"CountVect\")\n",
    "\n",
    "# tfidf\n",
    "tfidf_avg_runtimes = np.array([.011231791973114014, .02165952920913696, .026416730880737305, .03216578960418701, .04337368011474609])\n",
    "plt.plot(numTweets, tfidf_avg_runtimes, label=\"TFIDF\")\n",
    "\n",
    "# brown\n",
    "brown_avg_runtimes = np.array([31.487934696674348, 32.487717390060425, 29.90742540359497, 61.54061765670777, 46.681753146648404])\n",
    "plt.plot(numTweets, brown_avg_runtimes, label=\"Brown\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Query Time of Different Data Representations with Varying Number of Tweets Stored\")\n",
    "plt.xlabel(\"Number of Tweets Stored\")\n",
    "plt.ylabel(\"Query Time (sec)\")\n",
    "plt.legend(bbox_to_anchor=(1.1,1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF and countvect together\n",
    "plt.plot(numTweets, countvect_avg_runtimes, label=\"CountVect\")\n",
    "plt.plot(numTweets, tfidf_avg_runtimes, label=\"TFIDF\")\n",
    "plt.title(\"Query Time of Different Data Representations with Varying Number of Tweets Stored\")\n",
    "plt.xlabel(\"Number of Tweets Stored\")\n",
    "plt.ylabel(\"Query Time (sec)\")\n",
    "plt.legend(bbox_to_anchor=(1.1,1.05))\n",
    "plt.show()\n",
    "\n",
    "# Just brown\n",
    "plt.plot(numTweets, brown_avg_runtimes, label=\"Brown\", color='green')\n",
    "plt.title(\"Query Time of Different Data Representations with Varying Number of Tweets Stored\")\n",
    "plt.xlabel(\"Number of Tweets Stored\")\n",
    "plt.ylabel(\"Query Time (sec)\")\n",
    "plt.legend(bbox_to_anchor=(1.1,1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5f96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
